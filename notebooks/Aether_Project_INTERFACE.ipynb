{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8soQcIju-u2r",
        "outputId": "4a67b310-e202-4ef4-8d21-890f9bb18d08"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we mounted Google Drive to our Colab environment. This allows our group to access, save, and load files directly from Google Drive, such as our best-performing model, tokenizers, datasets, and output Excel files. By connecting Drive, we can ensure that all important files are stored persistently and easily shared among team members."
      ],
      "metadata": {
        "id": "GexbDdPC3YT3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07ef6Dpb-jO8",
        "outputId": "ee6c86ca-7656-4f99-ea74-6d97ff053c75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.121.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.49.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (5.4.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (1.5.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=14296bcd3d7bd35986d5d5d0986d53ba2287ccfa34f58de960e75d060fdca93d\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: portalocker, colorama, sacrebleu, rouge-score\n",
            "Successfully installed colorama-0.4.6 portalocker-3.2.0 rouge-score-0.1.2 sacrebleu-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio sacrebleu rouge-score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, our group installed Gradio, a Python library that allows us to create an interactive web-based interface for our grammar correction model. With Gradio, we can easily test the model by inputting sentences and instantly viewing the corrected outputs, making it simple to demonstrate and explore the model’s performance in real time."
      ],
      "metadata": {
        "id": "PnBmZvVD3muy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Define the path to your pre-trained T5 model on Google Drive\n",
        "gdrive_model_path = \"/content/drive/My Drive/best_model\"\n",
        "\n",
        "gdrive_tokenizer = T5Tokenizer.from_pretrained(gdrive_model_path)\n",
        "gdrive_model = T5ForConditionalGeneration.from_pretrained(gdrive_model_path)\n",
        "\n",
        "model = gdrive_model\n",
        "tokenizer = gdrive_tokenizer\n",
        "\n",
        "print(f\"Successfully loaded T5 tokenizer and model from: {gdrive_model_path}\")\n",
        "print(\"Model and tokenizer loaded from local path successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTaRUC9L-jsY",
        "outputId": "655ed53e-bdac-4a1b-8943-410d74a27be5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded T5 tokenizer and model from: /content/drive/My Drive/best_model\n",
            "Model and tokenizer loaded from local path successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, our group loaded the pre-trained T5 grammar correction model and its tokenizer directly from Google Drive. By specifying the path to the saved model, we ensure that the exact trained weights and vocabulary are used for inference. This allows us to run predictions and test the model without retraining. The print statements confirm that both the model and tokenizer were successfully loaded and ready for use."
      ],
      "metadata": {
        "id": "ImvhH5qB3rcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "def correct(sentence):\n",
        "    inputs = tokenizer(\"grammar: \" + sentence, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_length=128)\n",
        "    corrected = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return corrected\n",
        "\n",
        "def compute_bleu(original, corrected):\n",
        "    bleu = sacrebleu.corpus_bleu([corrected], [[original]])\n",
        "    return round(bleu.score, 2)\n",
        "\n",
        "def compute_rouge(original, corrected):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(original, corrected)\n",
        "\n",
        "    result = {\n",
        "        \"ROUGE-1\": round(scores[\"rouge1\"].fmeasure, 3),\n",
        "        \"ROUGE-L\": round(scores[\"rougeL\"].fmeasure, 3)\n",
        "    }\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "hOz2ZH8h-nSS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, our group defined functions to use the T5 model for grammar correction and to evaluate its output. The correct function takes an input sentence, prepends a task prefix (\"grammar: \"), tokenizes it, and uses the model to generate a corrected version.\n",
        "\n",
        "Additionally, we defined functions to compute evaluation metrics for the model’s output. compute_bleu calculates a BLEU score between the corrected sentence and the original reference, while compute_rouge calculates ROUGE-1 and ROUGE-L scores, providing a structured way to assess the quality of the corrections.\n",
        "\n",
        "This setup allows us to quickly run the model and measure its performance on individual sentences or datasets."
      ],
      "metadata": {
        "id": "_X93iy723xpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_file(file):\n",
        "    text = file.read().decode()\n",
        "    lines = text.split(\"\\n\")\n",
        "    corrected = [correct(line) for line in lines if line.strip() != \"\"]\n",
        "    return \"\\n\".join(corrected)\n"
      ],
      "metadata": {
        "id": "1_0zs_4a-pD0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, our group created a function to apply the grammar correction model to the contents of an uploaded text file. The correct_file function reads the file, splits it into individual lines, applies the correct function to each non-empty line, and then joins the corrected lines back together.\n",
        "\n",
        "This allows users to upload a text file and automatically receive a fully corrected version, making the model practical for batch corrections rather than just single sentences."
      ],
      "metadata": {
        "id": "_wi0K-iW30vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "custom_css = \"\"\"\n",
        "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');\n",
        "\n",
        "* {\n",
        "    font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\n",
        "}\n",
        "\n",
        "body {\n",
        "    background-color: #ffffff;\n",
        "    color: #1a1a1a;\n",
        "}\n",
        "\n",
        ".gradio-container {\n",
        "    max-width: 900px;\n",
        "    margin: 0 auto;\n",
        "}\n",
        "\n",
        "/* Header styling */\n",
        ".header-container h1 {\n",
        "    font-size: 32px;\n",
        "    font-weight: 700;\n",
        "    letter-spacing: -0.5px;\n",
        "    margin-bottom: 8px;\n",
        "    color: #000000;\n",
        "}\n",
        "\n",
        ".header-container p {\n",
        "    font-size: 14px;\n",
        "    font-weight: 400;\n",
        "    letter-spacing: 0.3px;\n",
        "    color: #666666;\n",
        "    text-transform: uppercase;\n",
        "    margin: 0;\n",
        "}\n",
        "\n",
        "/* Tabs styling */\n",
        ".tabs {\n",
        "    border-bottom: 1px solid #e5e5e5;\n",
        "}\n",
        "\n",
        ".tabitem {\n",
        "    padding: 20px 0;\n",
        "}\n",
        "\n",
        "/* Chatbot styling */\n",
        ".gr-chatbot {\n",
        "    border: 1px solid #e5e5e5;\n",
        "    border-radius: 8px;\n",
        "    background-color: #fafafa;\n",
        "}\n",
        "\n",
        ".gr-chatbot textarea {\n",
        "    border-radius: 6px;\n",
        "    border: 1px solid #e5e5e5;\n",
        "    font-size: 14px;\n",
        "    font-weight: 400;\n",
        "}\n",
        "\n",
        "/* Input field styling */\n",
        ".gr-textbox input {\n",
        "    border: 1px solid #e5e5e5;\n",
        "    border-radius: 6px;\n",
        "    font-size: 14px;\n",
        "    font-weight: 400;\n",
        "    padding: 12px;\n",
        "}\n",
        "\n",
        ".gr-textbox textarea {\n",
        "    border: 1px solid #e5e5e5;\n",
        "    border-radius: 6px;\n",
        "    font-size: 14px;\n",
        "    font-weight: 400;\n",
        "}\n",
        "\n",
        "/* Button styling */\n",
        ".gr-button {\n",
        "    border-radius: 6px;\n",
        "    font-weight: 500;\n",
        "    font-size: 14px;\n",
        "    letter-spacing: 0.3px;\n",
        "    border: none;\n",
        "    transition: all 0.2s ease;\n",
        "}\n",
        "\n",
        ".gr-button.primary {\n",
        "    background-color: #000000;\n",
        "    color: #ffffff;\n",
        "}\n",
        "\n",
        ".gr-button.primary:hover {\n",
        "    background-color: #333333;\n",
        "}\n",
        "\n",
        ".gr-button.secondary {\n",
        "    background-color: #f0f0f0;\n",
        "    color: #000000;\n",
        "    border: 1px solid #e5e5e5;\n",
        "}\n",
        "\n",
        ".gr-button.secondary:hover {\n",
        "    background-color: #e5e5e5;\n",
        "}\n",
        "\n",
        "/* Labels styling */\n",
        ".gr-textbox label,\n",
        ".gr-file label,\n",
        ".gr-chatbot label {\n",
        "    font-weight: 600;\n",
        "    font-size: 13px;\n",
        "    color: #1a1a1a;\n",
        "    letter-spacing: 0.2px;\n",
        "}\n",
        "\n",
        "/* Placeholder text */\n",
        ".gr-textbox input::placeholder {\n",
        "    color: #999999;\n",
        "    font-weight: 400;\n",
        "}\n",
        "\n",
        "/* Row and column spacing */\n",
        ".gr-row {\n",
        "    gap: 12px;\n",
        "}\n",
        "\n",
        ".gr-column {\n",
        "    gap: 12px;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Monochrome(), css=custom_css) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    <div class='header-container' style='text-align:center; padding: 30px 20px 20px;'>\n",
        "        <h1 style='color: #ffffff;'>Grammar Checker</h1>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tab(\"Chatbot\"):\n",
        "        with gr.Column():\n",
        "            chatbot = gr.Chatbot(label=\"Conversation\", height=500)\n",
        "\n",
        "        with gr.Row():\n",
        "            msg = gr.Textbox(\n",
        "                label=\"Enter your text\",\n",
        "                placeholder=\"Type here and press Enter...\",\n",
        "                scale=4\n",
        "            )\n",
        "            send_btn = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
        "\n",
        "        with gr.Row():\n",
        "            clear_btn = gr.Button(\"Clear Chat\", scale=1)\n",
        "\n",
        "        with gr.Row():\n",
        "            original_box = gr.Textbox(label=\"Original\", lines=2, interactive=False)\n",
        "            corrected_box = gr.Textbox(label=\"Corrected\", lines=2, interactive=False)\n",
        "\n",
        "        def chat(history, user_input):\n",
        "            corrected = correct(user_input)\n",
        "\n",
        "            history.append((user_input, corrected))\n",
        "            return (\n",
        "                history,\n",
        "                \"\",\n",
        "                user_input,\n",
        "                corrected\n",
        "            )\n",
        "\n",
        "        send_btn.click(\n",
        "            chat,\n",
        "            [chatbot, msg],\n",
        "            [chatbot, msg, original_box, corrected_box]\n",
        "        )\n",
        "\n",
        "        msg.submit(\n",
        "            chat,\n",
        "            [chatbot, msg],\n",
        "            [chatbot, msg, original_box, corrected_box]\n",
        "        )\n",
        "\n",
        "        clear_btn.click(lambda: None, None, chatbot)\n",
        "\n",
        "    with gr.Tab(\"Upload File\"):\n",
        "        with gr.Row():\n",
        "            file_input = gr.File(type=\"binary\", label=\"Upload .txt\")\n",
        "            file_output = gr.Textbox(label=\"Corrected Output\", lines=15)\n",
        "        file_btn = gr.Button(\"Correct File\", variant=\"primary\")\n",
        "        file_btn.click(correct_file, file_input, file_output)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "Y2fRKa2I-p-E",
        "outputId": "6e58d590-d660-48db-95db-d616f66970f2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-988700233.py:141: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"Conversation\", height=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f055857182469bd6e9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f055857182469bd6e9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, our group built a user-friendly interface using Gradio to make the T5 grammar correction model accessible for anyone, even without coding experience. We created a polished design using custom CSS to style the interface, including fonts, colors, buttons, textboxes, and layout.\n",
        "\n",
        "The interface has two main tabs:\n",
        "\n",
        "Chatbot Tab – allows users to type a sentence and get immediate grammar corrections. It displays the conversation history, the original sentence, and the corrected output side by side. Users can send messages by pressing Enter or clicking the Send button, and the chat can be cleared with a button.\n",
        "\n",
        "Upload File Tab – enables batch corrections by uploading a .txt file. Each line is processed using the correct_file function, and the fully corrected text is displayed in a textbox.\n",
        "\n",
        "This setup makes the grammar correction model highly interactive, visually appealing, and practical for both single-sentence corrections and large text files, bridging the gap between AI functionality and user experience."
      ],
      "metadata": {
        "id": "9lT981nF36Qn"
      }
    }
  ]
}